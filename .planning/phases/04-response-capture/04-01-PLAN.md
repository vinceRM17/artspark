---
phase: 04-response-capture
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - package.json
  - lib/schemas/response.ts
  - lib/constants/upload.ts
  - lib/services/imageUpload.ts
  - lib/services/responses.ts
  - lib/services/offlineQueue.ts
autonomous: true

must_haves:
  truths:
    - "Response schema validates prompt_id, image URLs, notes, and tags"
    - "Images are compressed to max 2048px and 0.8 quality before upload"
    - "Images upload to Supabase Storage as ArrayBuffer (not Blob/FormData)"
    - "Responses save to Supabase responses table linked to prompt by prompt_id"
    - "Offline queue stores pending uploads in AsyncStorage with metadata only (not base64)"
    - "Queue processes on connectivity restore using Promise.allSettled"
  artifacts:
    - path: "lib/schemas/response.ts"
      provides: "Response type + Zod schema + SQL migration docs"
      exports: ["Response", "responseSchema", "CreateResponseInput", "createResponseSchema"]
    - path: "lib/constants/upload.ts"
      provides: "Upload limits and compression config"
      exports: ["MAX_IMAGES", "COMPRESSION_QUALITY", "MAX_IMAGE_DIMENSION", "MAX_RETRY_COUNT", "QUEUE_EXPIRY_DAYS"]
    - path: "lib/services/imageUpload.ts"
      provides: "Image compression and Supabase Storage upload"
      exports: ["compressImage", "uploadImage", "uploadResponseImages"]
    - path: "lib/services/responses.ts"
      provides: "Response CRUD operations"
      exports: ["createResponse", "getResponsesForPrompt"]
    - path: "lib/services/offlineQueue.ts"
      provides: "Offline upload queue management"
      exports: ["queueUpload", "processQueue", "getQueueLength", "cleanupExpiredItems"]
  key_links:
    - from: "lib/services/imageUpload.ts"
      to: "lib/supabase.ts"
      via: "supabase.storage.from('responses').upload()"
      pattern: "supabase\\.storage.*upload"
    - from: "lib/services/responses.ts"
      to: "lib/supabase.ts"
      via: "supabase.from('responses').insert()"
      pattern: "supabase\\.from\\('responses'\\)"
    - from: "lib/services/responses.ts"
      to: "lib/services/imageUpload.ts"
      via: "uploadResponseImages call"
      pattern: "uploadResponseImages"
    - from: "lib/services/offlineQueue.ts"
      to: "lib/services/responses.ts"
      via: "createResponse call in queue processor"
      pattern: "createResponse"
---

<objective>
Build the complete data layer for response capture: schemas, constants, image upload service, response CRUD service, and offline upload queue.

Purpose: Establish the foundation that hooks and UI will consume. All Supabase integration, image compression, and offline reliability logic lives here.
Output: 5 new files (schema, constants, 3 services) + updated package.json with new dependencies
</objective>

<execution_context>
@/Users/vincecain/.claude/get-shit-done/workflows/execute-plan.md
@/Users/vincecain/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-response-capture/04-RESEARCH.md
@.planning/phases/03-prompt-generation/03-01-SUMMARY.md

@lib/supabase.ts
@lib/schemas/prompts.ts
@lib/services/prompts.ts
@lib/constants/preferences.ts
@package.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install dependencies, create response schema and upload constants</name>
  <files>
    package.json
    lib/schemas/response.ts
    lib/constants/upload.ts
  </files>
  <action>
**1. Install new dependencies:**
```bash
npx expo install expo-image-picker expo-file-system expo-sharing @react-native-community/netinfo
npm install react-native-compressor base64-arraybuffer
```

**2. Create `lib/constants/upload.ts`:**
Export these named constants (follow pattern from lib/constants/preferences.ts — simple exports, no classes):
- `MAX_IMAGES = 3` — max images per response
- `COMPRESSION_QUALITY = 0.8` — react-native-compressor quality (0-1 scale)
- `MAX_IMAGE_DIMENSION = 2048` — max width/height in pixels
- `MAX_RETRY_COUNT = 3` — max retries before dropping queued upload
- `QUEUE_EXPIRY_DAYS = 7` — expire queue items after 7 days
- `QUEUE_STORAGE_KEY = '@artspark:upload-queue'` — AsyncStorage key for offline queue
- `STORAGE_BUCKET = 'responses'` — Supabase Storage bucket name

**3. Create `lib/schemas/response.ts`:**
Follow pattern from lib/schemas/prompts.ts (TypeScript type + Zod schema + SQL migration in JSDoc).

Define `Response` type with fields:
- `id: string` (UUID)
- `user_id: string` (UUID FK to auth.users)
- `prompt_id: string` (UUID FK to prompts table)
- `image_urls: string[]` (array of Supabase Storage public URLs, 1-3 items)
- `notes: string | null` (optional text notes)
- `tags: string[]` (array of tag strings, can be empty)
- `created_at: string` (ISO timestamp)

Define `responseSchema` Zod schema matching the type.

Define `CreateResponseInput` type for the input to createResponse:
- `prompt_id: string` (required)
- `image_uris: string[]` (local file URIs before upload, 1-3 items)
- `notes: string | null` (optional)
- `tags: string[]` (optional, default empty)

Define `createResponseSchema` Zod schema for CreateResponseInput with validation:
- `prompt_id`: z.string().uuid()
- `image_uris`: z.array(z.string()).min(1).max(3)
- `notes`: z.string().max(500).nullable().default(null)
- `tags`: z.array(z.string().max(30)).max(10).default([])

Document SQL migration in JSDoc comment at top of file:
```sql
CREATE TABLE responses (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
  prompt_id UUID NOT NULL REFERENCES prompts(id) ON DELETE CASCADE,
  image_urls TEXT[] NOT NULL DEFAULT '{}',
  notes TEXT,
  tags TEXT[] NOT NULL DEFAULT '{}',
  created_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_responses_user ON responses(user_id);
CREATE INDEX idx_responses_prompt ON responses(prompt_id);

ALTER TABLE responses ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Users can read own responses"
  ON responses FOR SELECT USING (auth.uid() = user_id);

CREATE POLICY "Users can insert own responses"
  ON responses FOR INSERT WITH CHECK (auth.uid() = user_id);

CREATE POLICY "Users can update own responses"
  ON responses FOR UPDATE USING (auth.uid() = user_id);
```

Also document Storage bucket setup:
```sql
-- Run in Supabase Dashboard > Storage > Create bucket
-- Bucket name: responses
-- Public: false (use signed URLs for sharing)

-- Storage RLS policies (run in SQL Editor):
CREATE POLICY "Users can upload to own folder"
  ON storage.objects FOR INSERT
  WITH CHECK (bucket_id = 'responses' AND auth.uid()::text = (storage.foldername(name))[1]);

CREATE POLICY "Users can read own uploads"
  ON storage.objects FOR SELECT
  USING (bucket_id = 'responses' AND auth.uid()::text = (storage.foldername(name))[1]);
```
  </action>
  <verify>
1. `npx tsc --noEmit` passes (no type errors)
2. New packages appear in package.json dependencies: expo-image-picker, expo-file-system, expo-sharing, @react-native-community/netinfo, react-native-compressor, base64-arraybuffer
3. lib/constants/upload.ts exports MAX_IMAGES (3), COMPRESSION_QUALITY (0.8), MAX_IMAGE_DIMENSION (2048)
4. lib/schemas/response.ts exports Response type, responseSchema, CreateResponseInput, createResponseSchema
5. createResponseSchema validates: prompt_id is UUID, image_uris has 1-3 items, notes max 500 chars, tags max 10 items with max 30 chars each
  </verify>
  <done>
Response schema with Zod validation and SQL migration documented. Upload constants exported. All 6 new npm packages installed. TypeScript compiles cleanly.
  </done>
</task>

<task type="auto">
  <name>Task 2: Build image upload, response CRUD, and offline queue services</name>
  <files>
    lib/services/imageUpload.ts
    lib/services/responses.ts
    lib/services/offlineQueue.ts
  </files>
  <action>
**1. Create `lib/services/imageUpload.ts`:**

Import from: react-native-compressor (Image), expo-file-system, base64-arraybuffer (decode), lib/supabase, lib/constants/upload.

Export `compressImage(uri: string): Promise<string>`:
- Use `Image.compress(uri, { compressionMethod: 'auto', quality: COMPRESSION_QUALITY, maxWidth: MAX_IMAGE_DIMENSION, maxHeight: MAX_IMAGE_DIMENSION, returnableOutputType: 'uri' })`
- Return compressed URI
- Wrap in try/catch, log error and re-throw

Export `uploadImage(fileUri: string, userId: string, responseId: string, index: number): Promise<string>`:
- Read file as base64 using `FileSystem.readAsStringAsync(fileUri, { encoding: FileSystem.EncodingType.Base64 })`
- Convert to ArrayBuffer using `decode(base64)` from base64-arraybuffer
- Determine file extension from URI (default to 'jpg')
- Generate path: `${userId}/${responseId}_${index}_${Date.now()}.${ext}`
- Upload to Supabase Storage: `supabase.storage.from(STORAGE_BUCKET).upload(filePath, arrayBuffer, { contentType: 'image/${ext}', upsert: false })`
- On success, get public URL: `supabase.storage.from(STORAGE_BUCKET).getPublicUrl(data.path)`
- Return public URL string
- On error, throw with descriptive message

Export `uploadResponseImages(imageUris: string[], userId: string, responseId: string): Promise<string[]>`:
- Compress all images in parallel: `Promise.all(imageUris.map(uri => compressImage(uri)))`
- Upload all compressed images in parallel: `Promise.all(compressedUris.map((uri, i) => uploadImage(uri, userId, responseId, i)))`
- Return array of public URLs

**2. Create `lib/services/responses.ts`:**

Import from: lib/supabase, lib/schemas/response (types), lib/services/imageUpload (uploadResponseImages).

Export `createResponse(userId: string, input: CreateResponseInput): Promise<Response>`:
- Generate a temporary responseId using `crypto.randomUUID()` (for file naming in Storage)
- Call `uploadResponseImages(input.image_uris, userId, responseId)` to get public URLs
- Insert into Supabase responses table:
  ```
  supabase.from('responses').insert({
    id: responseId,
    user_id: userId,
    prompt_id: input.prompt_id,
    image_urls: imageUrls,
    notes: input.notes,
    tags: input.tags,
  }).select().single()
  ```
- Return the created response
- On error, throw with descriptive message

Export `getResponsesForPrompt(userId: string, promptId: string): Promise<Response[]>`:
- Query: `supabase.from('responses').select('*').eq('user_id', userId).eq('prompt_id', promptId).order('created_at', { ascending: false })`
- Return data array (empty array if none)

**3. Create `lib/services/offlineQueue.ts`:**

Import from: AsyncStorage, lib/constants/upload (QUEUE_STORAGE_KEY, MAX_RETRY_COUNT, QUEUE_EXPIRY_DAYS), lib/schemas/response (CreateResponseInput).

Define `QueuedUpload` type:
- `id: string` (unique queue item ID)
- `userId: string`
- `input: CreateResponseInput` (contains prompt_id, image_uris, notes, tags — metadata only, no base64)
- `timestamp: number` (Date.now() when queued)
- `retryCount: number` (starts at 0)

Internal helper `getQueue(): Promise<QueuedUpload[]>`:
- Read from AsyncStorage, parse JSON, return array (empty array if null)

Internal helper `saveQueue(queue: QueuedUpload[]): Promise<void>`:
- Stringify and save to AsyncStorage

Export `queueUpload(userId: string, input: CreateResponseInput): Promise<string>`:
- Create QueuedUpload with id = `upload_${Date.now()}_${Math.random().toString(36).slice(2)}`, retryCount = 0
- Add to queue, save
- Return the queue item id

Export `processQueue(uploadFn: (userId: string, input: CreateResponseInput) => Promise<any>): Promise<{ succeeded: number; failed: number }>`:
- Get queue. If empty, return { succeeded: 0, failed: 0 }
- Process with Promise.allSettled: `queue.map(item => uploadFn(item.userId, item.input))`
- For successful items: remove from queue
- For failed items: increment retryCount; if retryCount >= MAX_RETRY_COUNT, remove from queue (give up)
- Save updated queue
- Return counts

Export `getQueueLength(): Promise<number>`:
- Return queue array length

Export `cleanupExpiredItems(): Promise<number>`:
- Get queue, filter out items where `Date.now() - item.timestamp > QUEUE_EXPIRY_DAYS * 86400000`
- Save filtered queue, return count of removed items

NOTE: The offlineQueue stores file URIs (metadata), NOT base64 image data. This is critical — storing base64 in AsyncStorage causes performance degradation. The image files remain on device at their original URIs until upload succeeds.
  </action>
  <verify>
1. `npx tsc --noEmit` passes
2. lib/services/imageUpload.ts exports compressImage, uploadImage, uploadResponseImages
3. imageUpload.ts uses react-native-compressor Image.compress with quality 0.8 and max 2048px
4. imageUpload.ts uses decode() from base64-arraybuffer for ArrayBuffer conversion (NOT Blob/FormData)
5. lib/services/responses.ts exports createResponse, getResponsesForPrompt
6. responses.ts calls uploadResponseImages before inserting to database
7. lib/services/offlineQueue.ts exports queueUpload, processQueue, getQueueLength, cleanupExpiredItems
8. offlineQueue.ts stores only metadata (CreateResponseInput with file URIs), not base64 data
9. offlineQueue.ts removes items after MAX_RETRY_COUNT (3) failures
10. offlineQueue.ts removes items older than QUEUE_EXPIRY_DAYS (7) days
  </verify>
  <done>
Three services fully implemented: imageUpload (compress + ArrayBuffer upload to Supabase Storage), responses (CRUD with image upload orchestration), offlineQueue (AsyncStorage queue with retry/expiry logic). All services compile and follow established patterns. Image flow: compress -> base64 -> ArrayBuffer -> Supabase Storage.
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes with zero errors
2. All 5 new files exist: lib/schemas/response.ts, lib/constants/upload.ts, lib/services/imageUpload.ts, lib/services/responses.ts, lib/services/offlineQueue.ts
3. package.json contains all 6 new dependencies
4. Image compression uses react-native-compressor (NOT expo-image-manipulator)
5. Supabase Storage upload uses ArrayBuffer via decode() (NOT Blob/FormData)
6. Offline queue stores metadata only (file URIs, not base64)
7. Response schema links to prompts via prompt_id FK
8. SQL migrations documented in JSDoc for responses table + Storage RLS policies
</verification>

<success_criteria>
- Response schema defines type, Zod validation, and SQL migration matching prompts.ts pattern
- Upload constants export MAX_IMAGES=3, COMPRESSION_QUALITY=0.8, MAX_IMAGE_DIMENSION=2048
- Image upload service compresses, converts to ArrayBuffer, uploads to Supabase Storage
- Response service orchestrates image upload then database insert
- Offline queue manages AsyncStorage-based upload queue with retry (3 max) and expiry (7 days)
- All new files compile cleanly with existing codebase
</success_criteria>

<output>
After completion, create `.planning/phases/04-response-capture/04-01-SUMMARY.md`
</output>
